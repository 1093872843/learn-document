# RAG(检索增强生成)

## 为什么需要RAG技术

大模型预训练结束后，其内部的数据就固定了，无法从从外部获取新的数据。如果需要对特定行业开发Agent程序，单单使用大模型是无法满足知识需求的。比如你不可能询问大模型你们公司今年的财务数据统计结果，这是公司内部的私有数据，不可能包含在大模型的预训练数据中。此时为了让大模型新增这些知识，从难到易有四种方式。

- 重新训练或从头构建模型：成本高，更新数据困难。
- 微调模型(fine tuning)：成本高，更新数据困难。
- 动态提示（RAG是其中的一种方式）：需要提供外部文档，需要开发代码；更新数据方便；
- 简单提示工程：只需要修改面对大模型的提示词就可

## 什么是RAG

检索增强生成（RAG）是指对大型语言模型输出进行优化，RAG 事实上是在传统信息检索技术的基础上，结合生成模型的一种增强型方法。使其能够在生成响应之前引用训练数据来源之外的权威知识库,它的核心思想是通过结合外部的知识库或文档检索机制，增强生成模型的表现。

它的工作原理如下：

1. 检索阶段

    在生成回答之前，RAG会先从一个大型文档库（例如Wikipedia）中检索相关的信息。这些信息通常是与输入的查询或任务相关的文本。

2. 生成阶段

    获取到相关文档后，RAG模型将这些文档作为上下文输入到生成模型中，然后生成最终的答案或文本。

RAG相比微调具备的优势，不仅能依赖于模型本身的训练数据，还能实时从外部知识库获取最新的、相关的知识，从而生成更为准确和详细的回答。

## 实现RAG的框架或方式

- LLM + FAISS

    实现基于文本的RAG,FAISS（Facebook AI Similarity Search）是一个高效的向量搜索库，专门用于快速相似性搜索，主要应用于大规模向量数据的最近邻搜索。使用大模型api和FAISS手动实现数据向量存储搜索，适合本地小型向量存储，高速。

    缺点：需要较多的手动配置：设置 FAISS 索引和 LLM 之间的连接可能需要一定的工作量。集成复杂：需要开发者处理模型的选择、向量化、索引构建和查询处理。

- LlamaIndex

    [案例](./LlamaIndex)

    LlamaIndex（原名 GPT Index） 是一个专为大语言模型（LLM）优化的知识检索框架，用于构建 RAG（Retrieval-Augmented Generation，检索增强生成）系统。LlamaIndex 提供了抽象化的接口，使得开发者能够更方便地配置、索引和查询，无需手动管理底层细节（如 FAISS 索引）。

    LlamaIndex内置默认使用open AI提供的模型，若要使用其他模型，需要自定义配置类，使用较为复杂。

- LangChain

    快速开发，适合 API 级 RAG，开发快速但封装过多，复杂。