# 快速开始

本例以 langchain 调用`open ai`模型创建简单的调用模型程序

## python环境准备

1. 安装python环境
2. 安装基础依赖

```linux
pip install langchain
pip install -qU "langchain[openai]"
```

## 如何发起聊天

```python
import getpass
import os
# 'sk-xxxxx'为AI模型对应的api-key
os.environ["OPENAI_API_KEY"] = 'input your api key'
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
# 初始化模型
model = init_chat_model("gpt-4o-mini", model_provider="openai")
# 发送信息
model.invoke([{"role": "user", "content": "Hello"}])
```

## 如何使用prompt模板创建提示词

```linux
pip install langchain_core
pip install -qU "langchain[openai]"
```

```python

from langchain_core.prompts import ChatPromptTemplate
# 定义模板
system_template = "Translate the following from English into {language}"
# 定义prompt格式
prompt_template = ChatPromptTemplate.from_messages(
    [("system", system_template), ("user", "{text}")]
)
# 使用模板
prompt = prompt_template.invoke({"language": "Italian", "text": "hi!"})
print(prompt)
# 使用模板发送信息
model.invoke(prompt)
```

## 如何使用文档加载器加载外部文档并使用向量搜索进行检索

```linux
pip install  langchain-community
pip install -qU langchain-openai
```

```python
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

from langchain_ollama import OllamaEmbeddings


# 使用加载器加载pdf文档
file_path = "./example_data/1.pdf"
loader = PyPDFLoader(file_path)
docs = loader.load()
# print(docs)
# 切割文本以提高文本表示的质量，提高嵌入质量和检索的准确性
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200, add_start_index=True
)
all_splits = text_splitter.split_documents(docs)
print(all_splits)
# 将文本转换为向量
#需要本地安装Ollama，使用Ollama内的llama3:8b Embedding模型进行数据转换。
embeddings = OllamaEmbeddings(model="llama3:8b")
# 存储向量，这里我们使用内存存储。
vector_store = InMemoryVectorStore(embeddings)
ids = vector_store.add_documents(documents=all_splits)
results = vector_store.similarity_search(
    "input some question about content of pdf"
)
print(results[0])
```

## 如何使用聊天模型在返回的非结构化文本回答中提取出需要的结构化数据

_该功能仅适用于支持工具调用的模型_

```python
from langchain_deepseek import ChatDeepSeek
from langchain_core.prompts import ChatPromptTemplate

# 定义数据校验
class Person(BaseModel):
    name: Optional[str] = Field(default=None, description="The name of the person")
    hair_color: Optional[str] = Field(
        default=None, description="The color of the person's hair if known"
    )
    height_in_meters: Optional[str] = Field(
        default=None, description="Height measured in meters"
    )

llm =  ChatDeepSeek(
        model="deepseek-chat",
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
        # other params...
    )
structured_llm = llm.with_structured_output(schema=Person)
text = "Alan Smith is 6 feet tall and has blond hair."
resp = structured_llm.invoke(text)
print(resp)

```
