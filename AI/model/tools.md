# 一些辅助用的工具库

## Python库

- [tiktoken](https://github.com/openai/tiktoken) 

    tiktoken 是 OpenAI 官方提供的 tokenizer（分词器）。用于计算 GPT 模型输入的 token 数量，以及高效地进行文本 token 处理。包括计算 token 数量，优化输入文本（减少 token 消耗，降低 API 成本），切割长文本（方便管理大文本数据）。
