# 模型

## 本地模型集成环境

- GPU，N卡
  
    多数模型的推理需要GPU计算，如果没有，会导致推理速度极大的降低

- 安装CUDA，加速模型的训练和推理

## 模型仓库

- [hugging Face](https://huggingface.co/)

    专注于自然语言处理（NLP） 和 机器学习 的开源平台和社区,提供了一系列工具、库和资源，帮助开发者、研究人员和企业快速构建、训练和部署 AI 模型，尤其是基于 Transformer 架构的模型

- [modelscope](https://www.modelscope.cn/)

    ModelScope 是阿里巴巴达摩院（Alibaba DAMO Academy）推出的 开源模型社区与平台，类似于 Hugging Face，但更聚焦于中文及多模态大模型场景。它提供丰富的预训练模型、数据集、工具链，以及云端开发环境，旨在帮助开发者和企业快速应用 AI 技术。 

- [Ollama](https://ollama.com/)

    Ollama 是一个本地 LLM 运行环境，它也拥有自己的模型仓库(量化模型)，专门用于 下载、运行和管理本地大模型，无需复杂的环境配置。但是需要注意的是Ollama内所有的模型都是量化后的模型，非原模型，这是为了减少现存需求，但是也会降低模型的精确度，是否要使用Ollama上下载的模型需要根据具体需求来定。